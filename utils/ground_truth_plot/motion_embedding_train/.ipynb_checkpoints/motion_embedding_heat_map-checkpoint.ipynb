{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "utils.py:41: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/virtual_envs/ani_python2.7/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/tornado/ioloop.py\", line 1073, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-9752c1e93e5e>\", line 4, in <module>\n",
      "    from other_utils import np_utils, sk_utils\n",
      "  File \"other_utils/sk_utils.py\", line 2, in <module>\n",
      "    import vis_util\n",
      "  File \"other_utils/vis_util.py\", line 6, in <module>\n",
      "    from matplotlib import pyplot as plt\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 71, in <module>\n",
      "    from matplotlib.backends import pylab_setup\n",
      "  File \"/virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 17, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use(\"Agg\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from other_utils import np_utils, sk_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "from termcolor import colored\n",
    "\n",
    "import model \n",
    "from hyperparams import Hyperparameters\n",
    "import graph \n",
    "from data_loader import Data_loader\n",
    "import model_componets as comps\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From model_componets.py:33: calling norm (from tensorflow.python.ops.linalg_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From commons/tf_transform.py:21: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From utils.py:36: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From model.py:15: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From model.py:22: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "\u001b[34mloading weights\u001b[0m\n",
      "WARNING:tensorflow:From /virtual_envs/ani_python2.7/local/lib/python2.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ../../../pose_embedding_train_full_view_norm_range_one/ent44_15j_32/weights/encoder_iter-799001\n",
      "\u001b[33mloaded pose_encoder weights\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from ../../../pose_embedding_train_full_view_norm_range_one/ent44_15j_32/weights/decoder_iter-799001\n",
      "\u001b[34mloaded pose_decoder weights\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from ../../../motion_embedding_train/ent_44_15j_32/BILSTM_TRAIN/weights/lstm_encoder/rule_based_motion_net_expt_seq304900\n",
      "\u001b[32mloaded pose lstm_encoder weights\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from ../../../motion_embedding_train/ent_44_15j_32/BILSTM_TRAIN/weights/lstm_decoder/rule_based_motion_net_expt_seq304900\n",
      "\u001b[31mloaded pose lstm_decoder weights\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "H = Hyperparameters ()\n",
    "\n",
    "D = Data_loader(H.data_path,H.seq_length,H.batch_size)\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(3)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "\n",
    "\n",
    "input_ph = tf.placeholder(tf.float32, shape= [None , H.num_joints ,3],name = 'skeleton_input')\n",
    "\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "x_input = input_ph\n",
    "\n",
    "x_input_view_norm,x_input_local,tr_mats = comps.root_relative_to_local(x_input)\n",
    "\n",
    "encoder_out = graph.apply_pose_encoder(input_ph)\n",
    "\n",
    "encoder_input = tf.reshape(encoder_out,(-1,H.seq_length,32))\n",
    "\n",
    "encoder_lstm_out = model.apply_encoder(encoder_input,name ='motion_encoder')\n",
    "\n",
    "z_state = encoder_lstm_out['z_state']\n",
    "\n",
    "z_outputs = encoder_lstm_out['z_outputs']\n",
    "\n",
    "\n",
    "decoder_lstm_out = model.apply_decoder(z_state,z_outputs,name = 'motion_decoder')\n",
    "\n",
    "motion_recon = decoder_lstm_out['x_recon']\n",
    "\n",
    "motion_recon_reshaped = tf.reshape(motion_recon,((-1,32)))\n",
    "\n",
    "pose_recon = graph.apply_pose_decoder(motion_recon_reshaped)#view norm\n",
    "\n",
    "pose_encoder_params = graph.get_network_params(\"Encoder_net\")\n",
    "\n",
    "pose_decoder_params = graph.get_network_params(\"Decoder_net\")\n",
    "\n",
    "param_lstm_encoder = model.get_network_params('motion_encoder')\n",
    "\n",
    "param_lstm_decoder = model.get_network_params('motion_decoder')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print colored(\"loading weights\",\"blue\")\n",
    "\n",
    "tf.train.Saver(pose_encoder_params).restore(sess,'../../../pose_embedding_train_full_view_norm_range_one/ent44_15j_32/weights/encoder_iter-799001') \n",
    "print colored(\"loaded pose_encoder weights\",\"yellow\")\n",
    "'../../../'\n",
    "\n",
    "tf.train.Saver(pose_decoder_params).restore(sess,'../../../pose_embedding_train_full_view_norm_range_one/ent44_15j_32/weights/decoder_iter-799001')\n",
    "print colored(\"loaded pose_decoder weights\",\"blue\")\n",
    "\n",
    "tf.train.Saver(param_lstm_encoder).restore(sess,tf.train.latest_checkpoint('../../../motion_embedding_train/ent_44_15j_32/BILSTM_TRAIN/weights/lstm_encoder/'))\n",
    "print colored(\"loaded pose lstm_encoder weights\",\"green\")\n",
    "\n",
    "tf.train.Saver(param_lstm_decoder).restore(sess,tf.train.latest_checkpoint('../../../motion_embedding_train/ent_44_15j_32/BILSTM_TRAIN/weights/lstm_decoder/'))\n",
    "print colored(\"loaded pose lstm_decoder weights\",\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1920, 15, 3)\n"
     ]
    }
   ],
   "source": [
    "train_batch = np.asarray(D.get_sequence_batch_train())\n",
    "\n",
    "train_batch = train_batch[:,0:30]\n",
    "\n",
    "train_batch = train_batch.reshape((-1,H.num_joints , 3))\n",
    "\n",
    "print train_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.5931652e-01 -2.1863572e-02  3.0903769e-01 ...  8.5306144e-01\n",
      "   1.0987277e+00 -3.4481454e-01]\n",
      " [ 8.6495924e-01 -1.1619635e+00 -9.7419560e-01 ... -1.1625103e-01\n",
      "  -5.1615781e-01 -4.2339396e-01]\n",
      " [-1.8296171e+00 -2.2285075e-01 -4.6256151e-02 ...  1.3163806e-01\n",
      "   1.3041538e+00  2.3284122e-01]\n",
      " ...\n",
      " [ 5.0585002e-01  5.8784330e-01  7.9621905e-01 ... -1.6843089e-01\n",
      "  -6.6029847e-01 -8.4831953e-01]\n",
      " [ 3.2611814e-01 -3.6807594e-01  4.2632222e-04 ...  4.7973490e-01\n",
      "   2.2590287e-01 -6.2181991e-01]\n",
      " [-1.4228463e+00  7.9451807e-02 -2.1116139e-01 ... -1.5083416e-01\n",
      "   1.4197749e+00  3.7644990e-02]]\n"
     ]
    }
   ],
   "source": [
    "feed_dict = {x_input : train_batch}\n",
    "\n",
    "pred_ops = sess.run(z_state,feed_dict=feed_dict)\n",
    "predictions = pred_ops\n",
    "\n",
    "predictions.shape\n",
    "print predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 2)\n",
      "(64, 128)\n",
      "(45, 45, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_transformed = pca.fit_transform(predictions)\n",
    "print X_transformed.shape\n",
    "\n",
    "data_reduced = np.dot(predictions - pca.mean_, pca.components_.T)\n",
    "data_original = np.dot(data_reduced, pca.components_) + pca.mean_\n",
    "\n",
    "print data_original.shape\n",
    "\n",
    "\n",
    "component1 = X_transformed[:,0]\n",
    "component2 = X_transformed[:,1]\n",
    "\n",
    "std1 = np.std(component1)\n",
    "std2 = np.std(component2)\n",
    "mean1 = np.mean(component1)\n",
    "mean2 = np.mean(component2)\n",
    "\n",
    "no = 1\n",
    "\n",
    "map_d = 45\n",
    "std1_dist = np.linspace(mean1 - no *std1,mean1 + no *std1 , map_d)\n",
    "\n",
    "std1_dist_e = np.expand_dims(std1_dist,axis =1)\n",
    "\n",
    "std2_dist = np.linspace(mean2 - no *std2,mean2 + no *std2 ,map_d)\n",
    "std2_dist_e = np.expand_dims(std2_dist,axis =1)\n",
    "\n",
    "arr = np.empty((map_d,map_d,2))\n",
    "\n",
    "for i in  range(map_d):\n",
    "    for j in range(map_d):\n",
    "        k1 = std1_dist_e[i]\n",
    "        k2 = std2_dist_e[j]\n",
    "        k_con = np.concatenate([k1,k2],axis = -1)\n",
    "    \n",
    "        arr[i][j]=k_con\n",
    "\n",
    "print arr.shape \n",
    "reshaped = arr.reshape((map_d*map_d,2))\n",
    "\n",
    "data_original = np.dot(reshaped, pca.components_) + pca.mean_\n",
    "# mean_proj  = np.dot(np.zeros((100,2)),pca.components_)+pca.mean_\n",
    "\n",
    "# print mean_proj.shape\n",
    "# print data_original.shape\n",
    "# mean_o  = np.mean(data_original,axis = 0)\n",
    "\n",
    "# print np.mean(np.abs(mean_o - pca.mean_))\n",
    "# print data_reduced.shape\n",
    "# print X_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# print component1.shape\n",
    "# plt.hist(component1, bins=30)\n",
    "# print np.mean(component1)\n",
    "# plt.ylabel('frequency');\n",
    "# plt.xlabel('motion embedding value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(component2, bins=10)\n",
    "\n",
    "# print np.mean(component2)\n",
    "# plt.ylabel('frequency');\n",
    "# plt.xlabel('motion embedding value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "(128,)\n",
      "('minimum vaue of mean ', -1.3008744)\n",
      "('minimum value of std ', 0.3847128)\n",
      "('maximum value of mean', 0.82456946)\n",
      "('maximum value of std', 1.8805026)\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(predictions, axis=0)\n",
    "std = np.std(predictions,axis=0)\n",
    "\n",
    "print mean.shape\n",
    "print std.shape\n",
    "\n",
    "print('minimum vaue of mean ', min(mean))\n",
    "print('minimum value of std ', min(std))\n",
    "print('maximum value of mean', max(mean))\n",
    "print('maximum value of std', max(std))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = mean+(no*std)\n",
    "sample_2 = mean-(no*std)\n",
    "sample_1 = np.reshape(sample_1 , (1,128))\n",
    "sample_2 = np.reshape(sample_2 , (1,128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(0,1, map_d)\n",
    "a = np.reshape(a, (map_d,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 64)\n"
     ]
    }
   ],
   "source": [
    "vertical = a*sample_1[:,:64] + (1-a)*sample_2[:,:64]\n",
    "\n",
    "assert (vertical[0] == sample_2[0,:64]).all()\n",
    "\n",
    "print vertical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 64)\n"
     ]
    }
   ],
   "source": [
    "horizontal = a*sample_1[:,64:] + (1-a)*sample_2[:,64:]\n",
    "\n",
    "assert (horizontal[0] == sample_2[0,64:]).all()\n",
    "\n",
    "print horizontal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = np.empty((map_d,map_d,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(map_d):\n",
    "    for j in range(map_d):\n",
    "        grid[i,j] = np.concatenate((vertical[i], horizontal[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 45, 128)\n",
      "(2025, 128)\n"
     ]
    }
   ],
   "source": [
    "grid_flat = np.reshape(grid, (-1,128))\n",
    "\n",
    "print grid.shape\n",
    "print grid_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mloading weights\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from ../../../pose_embedding_train_full_view_norm_range_one/ent44_15j_32/weights/encoder_iter-799001\n",
      "\u001b[33mloaded pose_encoder weights\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from ../../../pose_embedding_train_full_view_norm_range_one/ent44_15j_32/weights/decoder_iter-799001\n",
      "\u001b[34mloaded pose_decoder weights\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from ../../../motion_embedding_train/ent_44_15j_32/BILSTM_TRAIN/weights/lstm_encoder/rule_based_motion_net_expt_seq304900\n",
      "\u001b[32mloaded pose lstm_encoder weights\u001b[0m\n",
      "INFO:tensorflow:Restoring parameters from ../../../motion_embedding_train/ent_44_15j_32/BILSTM_TRAIN/weights/lstm_decoder/rule_based_motion_net_expt_seq304900\n",
      "\u001b[31mloaded pose lstm_decoder weights\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "state_ph = tf.placeholder(tf.float32,shape = [None,128],name = \"lstm_state\")\n",
    "\n",
    "z_outs = tf.stack([state_ph]*H.seq_length, 1)\n",
    "\n",
    "\n",
    "def decoder(z_state,z_outputs):\n",
    "    decoder_lstm_out = model.apply_decoder(z_state,z_outputs,name = 'motion_decoder')\n",
    "\n",
    "    motion_recon = decoder_lstm_out['x_recon']\n",
    "\n",
    "    motion_recon_reshaped = tf.reshape(motion_recon,((-1,32)))\n",
    "\n",
    "    pose_recon = graph.apply_pose_decoder(motion_recon_reshaped)#view norm\n",
    "\n",
    "    pose_decoder_params = graph.get_network_params(\"Decoder_net\")\n",
    "    \n",
    "    return pose_recon\n",
    "    \n",
    "print colored(\"loading weights\",\"blue\")\n",
    "\n",
    "tf.train.Saver(pose_encoder_params).restore(sess,'../../../pose_embedding_train_full_view_norm_range_one/ent44_15j_32/weights/encoder_iter-799001') \n",
    "print colored(\"loaded pose_encoder weights\",\"yellow\")\n",
    "\n",
    "tf.train.Saver(pose_decoder_params).restore(sess,'../../../pose_embedding_train_full_view_norm_range_one/ent44_15j_32/weights/decoder_iter-799001')\n",
    "print colored(\"loaded pose_decoder weights\",\"blue\")\n",
    "\n",
    "tf.train.Saver(param_lstm_encoder).restore(sess,tf.train.latest_checkpoint('../../../motion_embedding_train/ent_44_15j_32/BILSTM_TRAIN/weights/lstm_encoder/'))\n",
    "print colored(\"loaded pose lstm_encoder weights\",\"green\")\n",
    "\n",
    "tf.train.Saver(param_lstm_decoder).restore(sess,tf.train.latest_checkpoint('../../../motion_embedding_train/ent_44_15j_32/BILSTM_TRAIN/weights/lstm_decoder/'))\n",
    "print colored(\"loaded pose lstm_decoder weights\",\"red\")\n",
    " \n",
    "pred_ops_ph = decoder(state_ph,z_outs)\n",
    "\n",
    "pred_ops = sess.run(pred_ops_ph,feed_dict={state_ph : grid_flat})\n",
    "    \n",
    "predictions = pred_ops.reshape(-1,H.seq_length,H.num_joints,3)\n",
    "\n",
    "pred_ops_new = sess.run(pred_ops_ph,feed_dict={state_ph : data_original})\n",
    "    \n",
    "predictions_new = pred_ops_new.reshape(-1,H.seq_length,H.num_joints,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 30, 15, 3)\n",
      "(2025, 30, 15, 3)\n"
     ]
    }
   ],
   "source": [
    "print predictions.shape\n",
    "print predictions_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 30)\n"
     ]
    }
   ],
   "source": [
    "predictions = np.mean(predictions, axis=(-1,-2))\n",
    "predictions_new = np.mean(predictions_new,axis=(-1,-2))\n",
    "print predictions.shape\n",
    "# print predictions_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2025, 29)\n"
     ]
    }
   ],
   "source": [
    "velocity = predictions[:,1:] - predictions[:,:-1]\n",
    "\n",
    "speed = np.absolute(velocity)\n",
    "\n",
    "velocity_new = predictions_new[:,1:] - predictions_new[:,:-1]\n",
    "\n",
    "speed_new = np.absolute(velocity_new)\n",
    "\n",
    "\n",
    "print(speed.shape)\n",
    "# print(speed_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "speed  = np.mean(speed, axis=-1)\n",
    "\n",
    "speed = np.reshape(speed, (map_d,map_d))\n",
    "\n",
    "\n",
    "speed_new  = np.mean(speed_new, axis=-1)\n",
    "\n",
    "speed_new = np.reshape(speed_new, (map_d,map_d))\n",
    "\n",
    "# print speed_new.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_big_arr(arr):\n",
    "    big_speed = []\n",
    "    bigger_speed = []\n",
    "    no_inters = 5\n",
    "\n",
    "    for i in range(speed.shape[0]-1):\n",
    "        j = i + 1\n",
    "        c = np.array([np.linspace(a,b,no_inters + 2) for a,b in zip(speed[i],speed[j])]).T\n",
    "\n",
    "        if i == 0:\n",
    "            for k in range(c.shape[0]):\n",
    "                big_speed.append(c[k])\n",
    "        else :\n",
    "            for l in range(c.shape[0]):\n",
    "                if l == 0 :\n",
    "                    continue\n",
    "                else :\n",
    "                    big_speed.append(c[l])\n",
    "\n",
    "\n",
    "    print np.array(big_speed).shape\n",
    "\n",
    "\n",
    "    for u in range(np.array(big_speed).shape[0]):\n",
    "        k = big_speed[u]\n",
    "        new_arr = []\n",
    "        for i in range(len(k)-1):\n",
    "            j= i +1\n",
    "            interp = np.linspace(k[i],k[j],no_inters + 2)\n",
    "            if i == 0 :\n",
    "                for ele in interp:\n",
    "                    new_arr.append(ele)\n",
    "            else :\n",
    "                for m in range(len(interp)):\n",
    "                    if m ==0 : \n",
    "                        continue\n",
    "                    else :\n",
    "                        new_arr.append(interp[m])\n",
    "\n",
    "        bigger_speed.append(new_arr)\n",
    "    return bigger_speed\n",
    "    \n",
    "# print speed[i]\n",
    "# print speed[j]\n",
    "# print c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 45)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # import matplotlib\n",
    "# plt.imshow(speed, cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar()\n",
    "\n",
    "# # plt.savefig(\"test.png\",bbox_inches = 'tight',dpi=350);\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(8,8))\n",
    "# ax1 = fig.add_subplot(1,1,1)\n",
    "# first = ax1.imshow(make_big_arr(speed), cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar(first,ax = ax1)\n",
    "# plt.axis('off')\n",
    "# plt.savefig(\"./sigma\"+str(no)+\"_without_pca.png\",bbox_inches = 'tight',dpi = 350);\n",
    "# plt.close()\n",
    "\n",
    "fig2 = plt.figure(figsize=(8,8))\n",
    "ax2 = fig.add_subplot(1,1,1)\n",
    "second = ax2.imshow(make_big_arr(speed_new), cmap='hot', interpolation='nearest')\n",
    "plt.colorbar(second,ax = ax2)\n",
    "plt.axis('off')\n",
    "plt.savefig(\"./sigma\"+str(no)+\"_with_pca.png\",bbox_inches = 'tight',dpi = 350);\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "\n",
    "# ax2 = fig.add_subplot(1,1,1)\n",
    "\n",
    "# second = ax2.imshow(speed_new, cmap='hot', interpolation='nearest')\n",
    "# plt.colorbar(second,ax = ax2)\n",
    "# plt.axis('off')\n",
    "# plt.savefig(\"./sigma\"+str(no)+\"_with_pca.png\",bbox_inches = 'tight',dpi = 350);\n",
    "\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
